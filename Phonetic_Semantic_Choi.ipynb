{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Code partially from Choi et al. (2024): https://github.com/juice500ml/phonetic_semantic_probing/tree/24b85b648c6512d9fe4df4139c546482080fef4c\n",
    "\n",
    "Copyright (c) 2022, Puyuan Peng All rights reserved.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/15171531/miniconda3/envs/analysis_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from textgrids import TextGrid\n",
    "from functools import partial\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils_Phonetic_Semantic_Choi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_DISTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [42, 12, 25, 31, 69]\n",
    "N_SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2_path_audio = 'embeddings/wav2vec2/LibriSpeech_audioslicing/w2v2_LibriSpeech_audioslicing.pkl' \n",
    "\n",
    "fast_vgs_plus_path_audio = 'embeddings/fast_vgs/LibriSpeech_audioslicing/fast_vgs_plus_librispeech_audioslicing.pkl'\n",
    "\n",
    "w2v2_path_feat = 'embeddings/wav2vec2/LibriSpeech_featureslicing/w2v2_LibriSpeech_featureslicing.pkl'\n",
    "\n",
    "fast_vgs_plus_path_feat = 'embeddings/fast_vgs/LibriSpeech_featureslicing/fast_vgs_plus_LibriSpeech_featureslicing.pkl'\n",
    "\n",
    "data_path = 'exp2/' # TODO: set path\n",
    "\n",
    "figure_path = 'exp2/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134344/158519596.py:3: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  w2v2 = pickle.load(f)\n",
      "/tmp/ipykernel_134344/158519596.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  fast_vgs_plus = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "# load dataframes\n",
    "\n",
    "# audio slicing\n",
    "with open(w2v2_path_audio, \"rb\") as f:\n",
    "    df_w2v2_audio = pickle.load(f)\n",
    "with open(fast_vgs_plus_path_audio, \"rb\") as f:\n",
    "    df_fast_vgs_audio = pickle.load(f)\n",
    "\n",
    "#feature slicing\n",
    "with open(w2v2_path_feat, \"rb\") as f:\n",
    "    df_w2v2_feat = pickle.load(f)\n",
    "with open(fast_vgs_plus_path_feat, \"rb\") as f:\n",
    "    df_fast_vgs_feat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create the wordmaps </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3326/3326 [00:01<00:00, 1764.15it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 10477.64it/s]\n",
      "Finding homophones: 100%|██████████| 3326/3326 [29:30<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3352/3352 [00:00<00:00, 3765.73it/s]\n",
      "100%|██████████| 3352/3352 [00:00<00:00, 10916.07it/s]\n",
      "Finding homophones: 100%|██████████| 3352/3352 [30:06<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3335/3335 [00:00<00:00, 3719.11it/s]\n",
      "100%|██████████| 3335/3335 [00:00<00:00, 10663.12it/s]\n",
      "Finding homophones: 100%|██████████| 3335/3335 [29:32<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3354/3354 [00:00<00:00, 3882.21it/s]\n",
      "100%|██████████| 3354/3354 [00:00<00:00, 10832.01it/s]\n",
      "Finding homophones: 100%|██████████| 3354/3354 [30:07<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [00:00<00:00, 3784.82it/s]\n",
      "100%|██████████| 3305/3305 [00:00<00:00, 10722.07it/s]\n",
      "Finding homophones: 100%|██████████| 3305/3305 [28:47<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# code from Choi et al. (2024): https://github.com/juice500ml/phonetic_semantic_probing/tree/24b85b648c6512d9fe4df4139c546482080fef4c \n",
    "for seed in SEEDS:\n",
    "    set_seed(seed)\n",
    "    print(f\"Seed: {seed}\")\n",
    "\n",
    "    # sample indices (does not matter which of the four dataframes you use here, as \n",
    "    # they all contain the same words. Words matter here, embeddings will come into play later)\n",
    "    indices = random.sample(range(len(df_w2v2_audio)), N_SAMPLES)\n",
    "\n",
    "    # filter dataframes\n",
    "    df_filtered_w2v2 = df_w2v2_audio.iloc[indices]\n",
    "\n",
    "    # get words\n",
    "    words = set(df_filtered_w2v2.text.unique())\n",
    "\n",
    "    # get phones for words\n",
    "    text2phones = {row.text: tuple(row.phones) for row in df_filtered_w2v2.itertuples()}\n",
    "\n",
    "    # get synonym maps\n",
    "    synonym_map = get_synonym_map(words, df_filtered_w2v2, text2phones)\n",
    "    not_filtered_synonym_map = get_synonym_map(words, df_filtered_w2v2, text2phones, threshold=-1)\n",
    "\n",
    "    # get homophone maps\n",
    "    homophone_map = get_homophone_map(words, not_filtered_synonym_map, df_filtered_w2v2, text2phones)\n",
    "\n",
    "    with open(f'{data_path}wordmap_{seed}.pkl', \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"indices\": indices,\n",
    "            \"synonym_map\": synonym_map,\n",
    "            \"homophone_map\": homophone_map,\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp1/semantic_categories.json', 'r') as f:\n",
    "    sem_categories = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slicing in ['audioslice', 'featslice']:\n",
    "    if slicing == 'audioslice':\n",
    "        df_w2v2 = df_w2v2_audio\n",
    "        df_fast_vgs_plus = df_fast_vgs_audio\n",
    "    else:\n",
    "        df_w2v2 = df_w2v2_feat\n",
    "        df_fast_vgs_plus = df_fast_vgs_feat\n",
    "    cos_sims_w2v2 = []\n",
    "    cos_sims_fast_vgs_plus = []\n",
    "    words = []\n",
    "    for layer_idx in range(12):\n",
    "        word_pairs = set()\n",
    "        print(f'########### Layer {layer_idx} ###########')\n",
    "        layer = f'layer_{layer_idx}'\n",
    "        layer_dists_w2v2 = []\n",
    "        layer_dists_fast_vgs_plus = []\n",
    "        for cat, data in sem_categories.items():\n",
    "            speakers_counter = defaultdict(int)\n",
    "            print(f'########### Category {cat} ###########')\n",
    "            for word_i in data['words']:\n",
    "                for word_j in data['words']:\n",
    "                    if word_i == word_j or tuple(sorted((word_i, word_j))) in word_pairs:\n",
    "                        continue\n",
    "                    word_pairs.add(tuple(sorted((word_i, word_j))))\n",
    "                    sub_df_w2v2_i = df_w2v2[df_w2v2['text'] == word_i]\n",
    "                    sub_df_fast_vgs_plus_i = df_fast_vgs_plus[df_fast_vgs_plus['text'] == word_i]\n",
    "\n",
    "                    sub_df_w2v2_j = df_w2v2[df_w2v2['text'] == word_j]\n",
    "                    sub_df_fast_vgs_plus_j = df_fast_vgs_plus[df_fast_vgs_plus['text'] == word_j]\n",
    "\n",
    "                    if len(sub_df_w2v2_i) == 0 or len(sub_df_w2v2_j) == 0:\n",
    "                        continue\n",
    "                    if word_i not in words:\n",
    "                        words.append(word_i)\n",
    "                    for idx_i, row_i in sub_df_w2v2_i.iterrows():\n",
    "                        for idx_j, row_j in sub_df_w2v2_j.iterrows():\n",
    "                            layer_dists_w2v2.append(cos_sim(row_i['w2v2_embeddings'][layer], row_j['w2v2_embeddings'][layer]))\n",
    "\n",
    "                    for idx_i, row_i in sub_df_fast_vgs_plus_i.iterrows():\n",
    "                        for idx_j, row_j in sub_df_fast_vgs_plus_j.iterrows():\n",
    "                            layer_dists_fast_vgs_plus.append(cos_sim(row_i['fast_vgs_plus_embeddings'][layer], row_j['fast_vgs_plus_embeddings'][layer]))\n",
    "        \n",
    "        cos_sims_w2v2.append(np.mean(layer_dists_w2v2))\n",
    "        cos_sims_fast_vgs_plus.append(np.mean(layer_dists_fast_vgs_plus))\n",
    "    with open(f'{data_path}sem_cats_dists_{slicing}.pkl', \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"w2v2\": cos_sims_w2v2,\n",
    "            \"fast_vgs_plus\": cos_sims_fast_vgs_plus,\n",
    "        }, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on Choi et al. (2024): https://github.com/juice500ml/phonetic_semantic_probing/tree/24b85b648c6512d9fe4df4139c546482080fef4c \n",
    "\n",
    "for slicing in ['audioslice', 'featslice']:\n",
    "    seedwise_dists_w2v2 = []   # list of dicts (key is sampler, values are the 12 layers (mean distance))\n",
    "    seedwise_dists_fast_vgs_plus = []\n",
    "    for seed in SEEDS:\n",
    "        dists_path_w2v2 = Path(f'{data_path}/dists/w2v2_{slicing}_seed-{seed}.pkl')\n",
    "        dists_path_fast_vgs_plus = Path(f'{data_path}dists/fast_vgs_plus_{slicing}_seed-{seed}.pkl')\n",
    "        if dists_path_w2v2.exists() and dists_path_fast_vgs_plus.exists() and LOAD_DISTS:\n",
    "            dists_w2v2 = pickle.load(open(dists_path_w2v2, 'rb'))\n",
    "            dists_fast_vgs_plus = pickle.load(open(dists_path_fast_vgs_plus, 'rb'))\n",
    "        else:\n",
    "\n",
    "            wordmap = pickle.load(open(f'exp2/wordmap_{seed}.pkl', 'rb'))\n",
    "\n",
    "            if slicing == 'audioslice':\n",
    "                df_w2v2 = df_w2v2_audio\n",
    "                df_fast_vgs_plus = df_fast_vgs_audio\n",
    "            else:\n",
    "                df_w2v2 = df_w2v2_feat\n",
    "                df_fast_vgs_plus = df_fast_vgs_feat\n",
    "\n",
    "            df_w2v2_filtered = df_w2v2.iloc[wordmap['indices']]\n",
    "            df_fast_vgs_plus_filtered = df_fast_vgs_plus.iloc[wordmap['indices']]\n",
    "\n",
    "            dists_w2v2 = defaultdict(list)\n",
    "            dists_fast_vgs_plus = defaultdict(list)\n",
    "            for layer_idx in tqdm(range(12)):\n",
    "                layer = f'layer_{layer_idx}'\n",
    "                for name, sampler in samplers.items():\n",
    "                    accumulator_w2v2 = defaultdict(list)\n",
    "                    accumulator_fast_vgs_plus = defaultdict(list)\n",
    "                    for l, r in tqdm(sampler(df_w2v2_filtered, wordmap), desc=f'{name} {layer}'):\n",
    "                            accumulator_w2v2[(df_w2v2_filtered.loc[l].text, df_w2v2_filtered.loc[r].text)].append(cos_sim(df_w2v2_filtered.loc[l].w2v2_embeddings[layer], df_w2v2_filtered.loc[r].w2v2_embeddings[layer]))\n",
    "                            accumulator_fast_vgs_plus[(df_fast_vgs_plus_filtered.loc[l].text, df_fast_vgs_plus_filtered.loc[r].text)].append(cos_sim(df_fast_vgs_plus_filtered.loc[l].fast_vgs_plus_embeddings[layer], df_fast_vgs_plus_filtered.loc[r].fast_vgs_plus_embeddings[layer]))\n",
    "                    dists_w2v2[name].append(np.array([np.array(v).mean() for v in accumulator_w2v2.values()]))\n",
    "                    dists_fast_vgs_plus[name].append(np.array([np.array(v).mean() for v in accumulator_fast_vgs_plus.values()]))\n",
    "            pickle.dump(dists_w2v2, open(dists_path_w2v2, 'wb'))\n",
    "            pickle.dump(dists_fast_vgs_plus, open(dists_path_fast_vgs_plus, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plots</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Audio slicing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {\n",
    "    \"w2v2_fast_vgs_plus\": {\n",
    "        \"left\": \"w2v2_seed-x.pkl\",\n",
    "        \"right\": \"fast_vgs_plus_seed-x.pkl\",\n",
    "        \"seeds\": [42, 12, 25, 31, 69],\n",
    "        \"speakers\": (\"everyone\", ),\n",
    "        \"normalizer\": (\"subtract\", \"subtract\"),\n",
    "        \"legend\": {\"loc\": \"center\", \"bbox_to_anchor\": (-0.2, 1.6), \"ncols\": 3},\n",
    "        \"title\": (\"wav2vec 2.0-base (Norm.)\", \"FaST-VGS+ (Norm.)\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "keys_with_sem = {\n",
    "    \"random\": (\"C0\", \"\", \"Random\"),\n",
    "    \"synonym\": (\"C1\", \"x\", \"Synonym\"),\n",
    "    \"homophone\": (\"C2\", \"o\", \"Near homophone\"),\n",
    "    \"speaker\": (\"C3\", \"|\", \"Same speaker\"),\n",
    "    \"same_word\": (\"C4\", \"^\", \"Same word\"),\n",
    "    \"semantic_categories\": (\"C5\", \"s\", \"Semantic categories\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on Choi et al. (2024): https://github.com/juice500ml/phonetic_semantic_probing/tree/24b85b648c6512d9fe4df4139c546482080fef4c \n",
    "\n",
    "for pair_key, meta in pairs.items():\n",
    "\n",
    "    with open( f'{data_path}sem_cats_dists_audioslice.pkl', \"rb\") as f:\n",
    "        sem_cats_dists = pickle.load(f)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\n",
    "    for loc, ax, normalizer, title in zip((\"left\", \"right\"), axes, meta[\"normalizer\"], meta[\"title\"]):\n",
    "        seedwise_dists = []\n",
    "        for seed_idx, speaker in product(range(len(meta[\"seeds\"])), meta[\"speakers\"]):\n",
    "            seed = meta['seeds'][seed_idx]\n",
    "            dists_path = Path(f'{data_path}dists') / meta[loc].replace(\"seed-x\", f\"seed-{seed}\")\n",
    "            dists = pickle.load(open(dists_path, \"rb\"))\n",
    "            seedwise_dists.append({\n",
    "                k: [mean_confidence_interval(v)[0] for v in vs]\n",
    "                for k, vs in dists.items()\n",
    "            })\n",
    "        agg_dists = {}\n",
    "        for key in seedwise_dists[0].keys():\n",
    "            agg_dists[key] = []\n",
    "            for layer in range(len(seedwise_dists[0][\"random\"])):\n",
    "                vs = [seedwise_dists[i][key][layer] for i in range(len(seedwise_dists))]\n",
    "                agg_dists[key].append(mean_confidence_interval(vs))\n",
    "        if loc == 'left':\n",
    "            agg_dists['semantic_categories'] = sem_cats_dists['w2v2']\n",
    "        else:\n",
    "            agg_dists['semantic_categories'] = sem_cats_dists['fast_vgs_plus']\n",
    "        \n",
    "        for key, tuples in agg_dists.items():\n",
    "            if key == 'semantic_categories':\n",
    "                value = tuples\n",
    "                if normalizer == \"subtract\":\n",
    "                    value -= np.array([t[0] for t in agg_dists[\"random\"]])\n",
    "                color, marker, label = keys_with_sem[key]\n",
    "                style = \"dotted\" if (key == \"random\" and normalizer == \"subtract\") else \"solid\"\n",
    "                ax.plot(value, label=label, marker=marker, color=color, linestyle=style)\n",
    "            else:\n",
    "                value = np.array([t[0] for t in tuples])\n",
    "                bound = np.array([t[1] for t in tuples])\n",
    "                if normalizer == \"subtract\":\n",
    "                    value -= np.array([t[0] for t in agg_dists[\"random\"]])\n",
    "                color, marker, label = keys_with_sem[key]\n",
    "                style = \"dotted\" if (key == \"random\" and normalizer == \"subtract\") else \"solid\"\n",
    "                ax.plot(value, label=label, marker=marker, color=color, linestyle=style)\n",
    "                ax.fill_between(np.arange(len(value)), value-bound, value+bound, alpha=0.2)\n",
    "\n",
    "        ax.set_yticks([0.0, 0.2, 0.4])\n",
    "        ax.yaxis.set_tick_params(labelbottom=True)\n",
    "        ax.set_xticks([0, 5, 10])\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(\"Norm. Cos. Sim.\" if normalizer == \"subtract\" else \"Cos. sim.\")\n",
    "        ax.set_xlabel(\"Layer Index\")\n",
    "        if title in (\"HuBERT-large (Norm.)\", \"Audio slicing (Norm.)\", \"Center pooling (Norm.)\", \"Centroid pooling (Norm.)\"):\n",
    "            ax.set_ylim(-0.02, 0.3)\n",
    "    plt.tight_layout()\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    label_order = ['Random', 'Near homophone', 'Same word',\n",
    "                     'Synonym', 'Same speaker', 'Semantic categories']\n",
    "\n",
    "    label_to_handle = {label: handle for label, handle in zip(labels, handles)}\n",
    "\n",
    "    sorted_handles = [label_to_handle[label] for label in label_order if label in label_to_handle]\n",
    "    sorted_labels = [label for label in label_order if label in label_to_handle]\n",
    "\n",
    "    plt.legend(sorted_handles, sorted_labels, **meta[\"legend\"])\n",
    "\n",
    "    plt.suptitle(f'Audio slicing', y=1.025, x=0.55, fontsize=18, fontstyle='italic')\n",
    "    plt.savefig(f\"{figure_path}{pair_key}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Feature slicing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {\n",
    "    \"w2v2_fast_vgs_plus_feature_slice\": {\n",
    "        \"left\": \"w2v2_featslice_seed-x.pkl\",\n",
    "        \"right\": \"fast_vgs_plus_featslice_seed-x.pkl\",\n",
    "        \"seeds\": [42, 12, 25, 31, 69],\n",
    "        \"speakers\": (\"everyone\", ),\n",
    "        \"normalizer\": (\"subtract\", \"subtract\"),\n",
    "        \"legend\": {\"loc\": \"center\", \"bbox_to_anchor\": (-0.2, 1.4), \"ncols\": 3},\n",
    "        \"title\": (\"wav2vec 2.0-base (Norm.)\", \"FaST-VGS+ (Norm.)\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "keys_with_sem = {\n",
    "    \"random\": (\"C0\", \"\", \"Random\"),\n",
    "    \"synonym\": (\"C1\", \"x\", \"Synonym\"),\n",
    "    \"homophone\": (\"C2\", \"o\", \"Near homophone\"),\n",
    "    \"speaker\": (\"C3\", \"|\", \"Same speaker\"),\n",
    "    \"same_word\": (\"C4\", \"^\", \"Same word\"),\n",
    "    \"semantic_categories\": (\"C5\", \"s\", \"Semantic categories\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on Choi et al. (2024): https://github.com/juice500ml/phonetic_semantic_probing/tree/24b85b648c6512d9fe4df4139c546482080fef4c \n",
    "\n",
    "for pair_key, meta in pairs.items():\n",
    "\n",
    "    with open( f'{data_path}sem_cats_dists_featslice.pkl', \"rb\") as f:\n",
    "        sem_cats_dists = pickle.load(f)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\n",
    "    for loc, ax, normalizer, title in zip((\"left\", \"right\"), axes, meta[\"normalizer\"], meta[\"title\"]):\n",
    "        seedwise_dists = []\n",
    "        for seed_idx, speaker in product(range(len(meta[\"seeds\"])), meta[\"speakers\"]):\n",
    "            seed = meta['seeds'][seed_idx]\n",
    "            dists_path = Path('exp2/dists') / meta[loc].replace(\"seed-x\", f\"seed-{seed}\")\n",
    "            dists = pickle.load(open(dists_path, \"rb\"))\n",
    "            seedwise_dists.append({\n",
    "                k: [np.nanmean(v) for v in vs]\n",
    "                for k, vs in dists.items()\n",
    "            })\n",
    "        agg_dists = {}\n",
    "        for key in seedwise_dists[0].keys():\n",
    "            agg_dists[key] = []\n",
    "            for layer in range(len(seedwise_dists[0][\"random\"])):\n",
    "                vs = [seedwise_dists[i][key][layer] for i in range(len(seedwise_dists))]\n",
    "                agg_dists[key].append(mean_confidence_interval(vs))\n",
    "        #print(agg_dists)\n",
    "        if loc == 'left':\n",
    "            agg_dists['semantic_categories'] = sem_cats_dists['w2v2']\n",
    "\n",
    "        else:\n",
    "            agg_dists['semantic_categories'] = sem_cats_dists['fast_vgs_plus']\n",
    "        \n",
    "        for key, tuples in agg_dists.items():\n",
    "            if key == 'semantic_categories':\n",
    "                value = tuples\n",
    "                if normalizer == \"subtract\":\n",
    "                    value -= np.array([t[0] for t in agg_dists[\"random\"]])\n",
    "                color, marker, label = keys_with_sem[key]\n",
    "                style = \"dotted\" if (key == \"random\" and normalizer == \"subtract\") else \"solid\"\n",
    "                ax.plot(value, label=label, marker=marker, color=color, linestyle=style)\n",
    "            else:\n",
    "                value = np.array([t[0] for t in tuples])\n",
    "                bound = np.array([t[1] for t in tuples])\n",
    "                if normalizer == \"subtract\":\n",
    "                    value -= np.array([t[0] for t in agg_dists[\"random\"]])\n",
    "                color, marker, label = keys_with_sem[key]\n",
    "                style = \"dotted\" if (key == \"random\" and normalizer == \"subtract\") else \"solid\"\n",
    "                ax.plot(value, label=label, marker=marker, color=color, linestyle=style)\n",
    "                ax.fill_between(np.arange(len(value)), value-bound, value+bound, alpha=0.2)\n",
    "\n",
    "        ax.set_yticks([0.0, 0.015, 0.03, 0.045])\n",
    "        ax.yaxis.set_tick_params(labelbottom=True)\n",
    "        ax.set_xticks([0, 5, 10])\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(\"Norm. Cos. Sim.\" if normalizer == \"subtract\" else \"Cos. sim.\")\n",
    "        ax.set_xlabel(\"Layer Index\")\n",
    "        if title in (\"HuBERT-large (Norm.)\", \"Audio slicing (Norm.)\", \"Center pooling (Norm.)\", \"Centroid pooling (Norm.)\"):\n",
    "            ax.set_ylim(-0.02, 0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ###\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    label_order = ['Random', 'Near homophone', 'Same word',\n",
    "                     'Synonym', 'Same speaker', 'Semantic categories']\n",
    "\n",
    "    label_to_handle = {label: handle for label, handle in zip(labels, handles)}\n",
    "\n",
    "    sorted_handles = [label_to_handle[label] for label in label_order if label in label_to_handle]\n",
    "    sorted_labels = [label for label in label_order if label in label_to_handle]\n",
    "\n",
    "    plt.suptitle(f'Feature slicing', y=1.025, x=0.55, fontsize=18, fontstyle='italic')\n",
    "    plt.savefig(f\"{figure_path}{pair_key}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
